from pathlib import Path

import cv2
import photoshop.api as ps
from photoshop import Session
import shutil
import numpy as np
from PIL import Image
import pillow_avif
from tqdm import tqdm
import torch
from torch.utils.data import DataLoader
import torch.nn.functional as F
from torchvision import transforms
import torchvision.models as models
import os

from train import ResizeWithPad, MetSegDataset, TARGET_SIZE, DEVICE


def isGrayMap(img, threshold=10, debug=False):
    """
    å…¥å‚ï¼š
    imgï¼šPILè¯»å…¥çš„å›¾åƒ
    thresholdï¼šåˆ¤æ–­é˜ˆå€¼ï¼Œå›¾ç‰‡3ä¸ªé€šé“é—´å·®çš„æ–¹å·®å‡å€¼å°äºé˜ˆå€¼åˆ™åˆ¤æ–­ä¸ºç°åº¦å›¾ã€‚
    é˜ˆå€¼è®¾ç½®çš„è¶Šå°ï¼Œå®¹å¿å‡ºç°å½©è‰²é¢ç§¯è¶Šå°ï¼›è®¾ç½®çš„è¶Šå¤§ï¼Œé‚£ä¹ˆå°±å¯ä»¥å®¹å¿å‡ºç°ä¸€å®šé¢ç§¯çš„å½©è‰²ï¼Œä¾‹å¦‚å¾®åšæˆªå›¾ã€‚
    å¦‚æœé˜ˆå€¼è®¾ç½®çš„è¿‡å°ï¼ŒæŸäº›ç°åº¦å›¾ç‰‡ä¼šè¢«æ¼æ£€ï¼Œè¿™æ˜¯å› ä¸ºæŸäº›é»‘ç™½ç…§ç‰‡å­˜åœ¨åè‰²ï¼Œä¾‹å¦‚å‘é»„çš„é»‘ç™½è€ç…§ç‰‡ã€
    å™ªå£°å¹²æ‰°å¯¼è‡´ç°åº¦å›¾ä¸åŒé€šé“é—´å€¼å‡ºç°åå·®ï¼ˆç†è®ºä¸ŠçœŸæ­£çš„ç°åº¦å›¾æ˜¯RGBä¸‰ä¸ªé€šé“çš„å€¼å®Œå…¨ç›¸ç­‰æˆ–è€…åªæœ‰ä¸€ä¸ªé€šé“ï¼Œ
    ç„¶è€Œå®é™…ä¸Šå„é€šé“é—´åƒç´ å€¼ç•¥å¾®æœ‰åå·®çœ‹èµ·æ¥ä»æ˜¯ç°åº¦å›¾ï¼‰
    å‡ºå‚ï¼š
    boolå€¼
    """
    if len(img.getbands()) == 1:
        return True
    img1 = np.asarray(img.getchannel(channel=0), dtype=np.int16)
    img2 = np.asarray(img.getchannel(channel=1), dtype=np.int16)
    img3 = np.asarray(img.getchannel(channel=2), dtype=np.int16)
    diff1 = (img1 - img2).var()
    diff2 = (img2 - img3).var()
    diff3 = (img3 - img1).var()
    diff_sum = (diff1 + diff2 + diff3) / 3.0
    if debug:
        print(f"å·®å¼‚å€¼ä¸ºï¼š{diff_sum}")
    if diff_sum <= threshold:
        return True
    else:
        return False


def infer_single_image(img_path, model, save_dir='', device=DEVICE, threshold=0.5):
    """å•å›¾æ¨ç†å¹¶ä¿å­˜æ©ç """
    # åŠ è½½åŸå›¾
    img = Image.open(img_path).convert("RGB")
    original_size = img.size
    img_base = os.path.splitext(os.path.basename(img_path))[0]

    # é¢„å¤„ç†
    transform = transforms.Compose([
        ResizeWithPad(TARGET_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    img_tensor = transform(img).unsqueeze(0).to(device)

    # æ¨ç†
    model.eval()
    with torch.no_grad():
        output = model(img_tensor)
        pred_mask = (output > threshold).float().squeeze(0).squeeze(0).cpu().numpy()
        pred_mask = (pred_mask * 255).astype(np.uint8)

    # è¿˜åŸåŸå›¾å°ºå¯¸
    pred_mask_img = Image.fromarray(pred_mask)
    target_w, target_h = TARGET_SIZE
    original_w, original_h = original_size
    scale = min(target_w / original_w, target_h / original_h)
    new_w = int(original_w * scale)
    new_h = int(original_h * scale)

    pad_left = (target_w - new_w) // 2
    pad_top = (target_h - new_h) // 2
    pred_mask_img = pred_mask_img.crop((pad_left, pad_top, pad_left + new_w, pad_top + new_h))

    pred_mask_img = pred_mask_img.resize(original_size, Image.NEAREST)

    # ä¿å­˜æ©ç 
    save_path = os.path.join(save_dir, f"{img_base}_pred_mask.png")
    pred_mask_img.save(save_path)
    return save_path


def test_model(model, weight_path, test_loader, test_out_dir, device=DEVICE):
    """æµ‹è¯•æ¨¡å¼ï¼šåŠ è½½æƒé‡ï¼Œå¯¹æµ‹è¯•é›†æ‰€æœ‰å›¾ç‰‡æ¨ç†"""
    # åŠ è½½æƒé‡
    model.load_state_dict(torch.load(weight_path, weights_only=True))
    print(f"âœ… åŠ è½½æƒé‡å®Œæˆï¼š{weight_path}")

    # æ¸…ç†å¹¶åˆ›å»ºæµ‹è¯•ç»“æœç›®å½•
    if os.path.exists(test_out_dir):
        shutil.rmtree(test_out_dir)
        print('ä»¥å¾€æµ‹è¯•ç»“æœå·²åˆ é™¤')
    os.makedirs(test_out_dir, exist_ok=True)

    # å¯¹æµ‹è¯•é›†é€å›¾æ¨ç†
    print("\nğŸ“ å¼€å§‹å¯¹æµ‹è¯•é›†æ¨ç†...")
    pbar = tqdm(test_loader, desc="æµ‹è¯•æ¨ç†")
    for batch in pbar:
        img_paths = batch["img_path"]
        for img_path in img_paths:
            infer_single_image(img_path, model, test_out_dir, device)

    print(f"âœ… æµ‹è¯•å®Œæˆï¼æ‰€æœ‰æ©ç å·²ä¿å­˜è‡³ï¼š{test_out_dir}")


def run_test(weight_path, test_out_dir, batch_size=12):
    """è¿è¡Œæµ‹è¯•çš„ä¸»å‡½æ•°"""
    # å®šä¹‰æµ‹è¯•é›†å˜æ¢
    val_test_transform = transforms.Compose([
        ResizeWithPad(TARGET_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å’ŒåŠ è½½å™¨
    test_dataset = MetSegDataset(split="test", transform=val_test_transform)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    # åˆå§‹åŒ–æ¨¡å‹å¹¶æµ‹è¯•
    from ResNetUNet import ResNetUNet
    model = ResNetUNet(n_channels=3, n_classes=1).to(DEVICE)
    test_model(model, weight_path, test_loader, test_out_dir, DEVICE)


def ps_auto_composite_layers(bg_img_path, top_img_path, mask_img_path, save_psd_path, auto_gray=False, cv2_align=True,
                             color_level=None, filter_blur=None, filter_sharp=None, do_action=None):
    """

    :param cv2_align:
    :param bg_img_path:
    :param top_img_path:
    :param mask_img_path:
    :param auto_gray:
    :param color_level: è‰²é˜¶çš„å‚æ•°ï¼Œæ¯”å¦‚ï¼šé»‘åœº12ã€ç™½åœº230ã€ç°åœº0.8 -> {'black': 12, 'white': 230, 'gray': 0.8}
    :param filter_blur: è¡¨é¢æ¨¡ç³Šçš„å‚æ•°ï¼Œæ¨èï¼šåŠå¾„3ã€é˜ˆå€¼8 -> {'radius': 3, 'threshold': 8}
    :param filter_sharp: USMé”åŒ–çš„å‚æ•°ï¼Œæ¨èï¼šæ•°é‡65ã€åŠå¾„1ã€é˜ˆå€¼8 -> {'quantity': 65, 'radius': 1, 'threshold': 8}
    :param do_action: å…³é—­å‰è¦è¿è¡Œçš„åŠ¨ä½œï¼Œæ¯”å¦‚['åŠ¨ä½œåˆ†ç»„å', 'åŠ¨ä½œå']
    :param save_psd_path:
    :return:
    """
    # ========== ç›¸å¯¹è·¯å¾„ â†’ PSæ”¯æŒçš„ç»å¯¹è·¯å¾„ï¼ˆå¿…åšï¼‰ ==========
    bg_img_path = os.path.abspath(os.path.normpath(bg_img_path))
    top_img_path = os.path.abspath(os.path.normpath(top_img_path))
    if mask_img_path is not None:
        mask_img_path = os.path.abspath(os.path.normpath(mask_img_path))
    save_psd_path = os.path.abspath(os.path.normpath(save_psd_path))

    # ========== æ–‡ä»¶æœ‰æ•ˆæ€§æ ¡éªŒ ==========
    file_check = [(bg_img_path, "åº•å›¾"), (top_img_path, "ä¸Šå±‚å›¾")]
    if mask_img_path is not None:
        file_check.append((mask_img_path, "MASKå›¾"))
    for path, name in file_check:
        if not os.path.exists(path):
            raise FileNotFoundError(f"âŒ {name}æ–‡ä»¶ä¸å­˜åœ¨ â†’ {path}")
    app = ps.Application()
    doc = app.open(bg_img_path)
    if doc.mode == 6:
        doc.changeMode(1)  # 1æ˜¯ç°åº¦ï¼Œ2æ˜¯RGBï¼Œ3æ˜¯CMYKï¼Œ6æ˜¯ç´¢å¼•
    bg_layer = doc.artLayers[0]
    bg_layer.name = "èƒŒæ™¯å›¾å±‚"
    # ========== ç°åº¦å›¾åˆ¤å®š ==========
    is_gray = isGrayMap(Image.open(bg_img_path))
    if auto_gray and doc.channels.length > 1 and is_gray:
        app.doJavaScript("app.activeDocument.changeMode(ChangeMode.GRAYSCALE);")
    # å¯¼å…¥å›¾å±‚å¹¶å¯¹é½
    if cv2_align:
        top_img_path = align_images(bg_img_path, top_img_path)
    with Session() as ps_:
        desc = ps_.ActionDescriptor
        desc.putPath(ps_.app.charIDToTypeID("null"), top_img_path)
        ps_.app.executeAction(ps_.app.charIDToTypeID("Plc "), desc)
    doc.activeLayer.rasterize(5)
    up_layer = doc.artLayers[0]
    up_layer.name = "ä¸Šå±‚å›¾å±‚"
    if not cv2_align:
        stdlib_js = open('stdlib.js', encoding='utf-8').read()
        stdlib_js += "Stdlib.loadSelection(doc, doc.artLayers.getByName('èƒŒæ™¯å›¾å±‚'), 'Trsp');Stdlib.crop(doc);"
        app.doJavaScript(stdlib_js)
    bg_layer.isBackgroundLayer = True
    # è‰²é˜¶
    if color_level and auto_gray and is_gray:
        app.doJavaScript(f"""
            var desc284 = new ActionDescriptor();
            var idpresetKind = stringIDToTypeID( "presetKind" );
            var idpresetKindType = stringIDToTypeID( "presetKindType" );
            var idpresetKindCustom = stringIDToTypeID( "presetKindCustom" );
            desc284.putEnumerated( idpresetKind, idpresetKindType, idpresetKindCustom );
            var list4 = new ActionList();
            var desc285 = new ActionDescriptor();
            var idChnl = charIDToTypeID( "Chnl" );
            var ref3 = new ActionReference();
            var idChnl = charIDToTypeID( "Chnl" );
            ref3.putEnumerated( idChnl, charIDToTypeID( "Ordn" ), charIDToTypeID( "Trgt" ) );
            desc285.putReference( idChnl, ref3 );
            var list5 = new ActionList();
            list5.putInteger( {color_level['black']} );
            list5.putInteger( {color_level['white']} );
            desc285.putList( charIDToTypeID( "Inpt" ), list5 );
            desc285.putDouble( charIDToTypeID( "Gmm " ), {color_level['gray']} );
            list4.putObject( charIDToTypeID( "LvlA" ), desc285 );
            desc284.putList( charIDToTypeID( "Adjs" ), list4 );
            executeAction( charIDToTypeID( "Lvls" ), desc284, DialogModes.NO );
        """)
    # è¡¨é¢æ¨¡ç³Š
    if filter_blur:
        app.doJavaScript(f"""
            var desc227 = new ActionDescriptor();
            desc227.putUnitDouble(charIDToTypeID("Rds "), charIDToTypeID("#Pxl"), {filter_blur['radius']});
            desc227.putInteger(charIDToTypeID("Thsh"), {filter_blur['threshold']} );
            executeAction(stringIDToTypeID("surfaceBlur"), desc227, DialogModes.NO );
        """)
    # USMé”åŒ–
    if filter_sharp:
        app.doJavaScript(f"""
            var desc256 = new ActionDescriptor();
            desc256.putUnitDouble(charIDToTypeID("Amnt"), charIDToTypeID("#Prc"), {filter_sharp['quantity']});
            desc256.putUnitDouble(charIDToTypeID("Rds "), charIDToTypeID("#Pxl"), {filter_sharp['radius']});
            desc256.putInteger(charIDToTypeID("Thsh"), {filter_sharp['threshold']});
            executeAction(idUnsM = charIDToTypeID("UnsM"), desc256, DialogModes.NO);
        """)
    if mask_img_path is not None:
        with Session() as ps_:
            desc = ps_.ActionDescriptor
            desc.putPath(ps_.app.charIDToTypeID("null"), mask_img_path)
            ps_.app.executeAction(ps_.app.charIDToTypeID("Plc "), desc)
        mask_layer = doc.artLayers[0]
        mask_layer.rasterize(5)
        mask_layer.name = "mask"
        # å°†ç™½è‰²åƒç´ è½½å…¥é€‰åŒº
        app.doJavaScript(r"""
            var desc = new ActionDescriptor();
            var ref = new ActionReference();
            ref.putProperty(stringIDToTypeID("channel"), stringIDToTypeID("selection"));
            desc.putReference(charIDToTypeID("null"), ref);
            desc.putInteger(charIDToTypeID("fzns"), 0); 
            desc.putDouble(stringIDToTypeID("H"), 0); 
            desc.putDouble(stringIDToTypeID("H_1"), 0); 
            desc.putEnumerated(stringIDToTypeID("sample"), stringIDToTypeID("sampleFrom"), stringIDToTypeID("currentLayer"));
            executeAction(stringIDToTypeID("colorRange"), desc, DialogModes.NO);
        """)
        mask_layer.visible = False
    doc.activeLayer = up_layer
    # å°†é€‰åŒºåº”ç”¨ä¸ºè’™ç‰ˆ
    app.doJavaScript(r"""
        try {
            var hasSelection = app.activeDocument.selection.bounds;
            var desc220 = new ActionDescriptor();
            var idChnl = charIDToTypeID( "Chnl" );
            desc220.putClass( charIDToTypeID( "Nw  " ), idChnl );
            var ref1 = new ActionReference();
            ref1.putEnumerated( idChnl, idChnl, charIDToTypeID( "Msk " ) );
            desc220.putReference( charIDToTypeID( "At  " ), ref1 );
            desc220.putEnumerated( charIDToTypeID( "Usng" ), charIDToTypeID( "UsrM" ), charIDToTypeID( "RvlS" ) );
            executeAction( charIDToTypeID( "Mk  " ), desc220, DialogModes.NO );
        } catch(e) {
            var desc219 = new ActionDescriptor();
            var idChnl = charIDToTypeID( "Chnl" );
            desc219.putClass( charIDToTypeID( "Nw  " ), idChnl );
            var idAt = charIDToTypeID( "At  " );
            var ref1 = new ActionReference();
            ref1.putEnumerated( idChnl, idChnl, charIDToTypeID( "Msk " ) );
            desc219.putReference( idAt, ref1 );
            desc219.putEnumerated( charIDToTypeID( "Usng" ), charIDToTypeID( "UsrM" ), charIDToTypeID( "RvlA" ) );
            executeAction( charIDToTypeID( "Mk  " ), desc219, DialogModes.NO );
            var desc226 = new ActionDescriptor();
            var idClr = charIDToTypeID( "Clr " );
            desc226.putEnumerated( charIDToTypeID( "Usng" ), charIDToTypeID( "FlCn" ), idClr );
            var desc227 = new ActionDescriptor();
            desc227.putUnitDouble( charIDToTypeID( "H   " ), charIDToTypeID( "#Ang" ), 299.992676 );
            desc227.putDouble( charIDToTypeID( "Strt" ), 0.000000 );
            desc227.putDouble( charIDToTypeID( "Brgh" ), 0.000000 );
            desc226.putObject( idClr, charIDToTypeID( "HSBC" ), desc227 );
            desc226.putUnitDouble( charIDToTypeID( "Opct" ), charIDToTypeID( "#Prc" ), 100.000000 );
            desc226.putEnumerated( charIDToTypeID( "Md  " ), charIDToTypeID( "BlnM" ), charIDToTypeID( "Nrml" ) );
            executeAction( charIDToTypeID( "Fl  " ), desc226, DialogModes.NO );
        }
    """)
    if do_action:
        app.doAction(do_action[1], do_action[0])
    # 72dpi
    app.doJavaScript("""
        var desc1 = new ActionDescriptor();
        desc1.putUnitDouble(charIDToTypeID('Rslt'), charIDToTypeID('#Rsl'), 72);
        executeAction(stringIDToTypeID('imageSize'), desc1, DialogModes.NO);
    """)
    doc.saveAs(save_psd_path, ps.PhotoshopSaveOptions())
    doc.close(ps.SaveOptions.DoNotSaveChanges)


def match_comics_2(folder_a, folder_b, match_from_son=False):
    r_ = '**/*' if match_from_son else '*'
    # å®šä¹‰å›¾åƒé¢„å¤„ç†
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    if os.path.exists('pth/resnet50-11ad3fa6.pth'):
        model = models.resnet50(weights=None)
        state_dict = torch.load('pth/resnet50-11ad3fa6.pth', map_location='cpu', weights_only=True)
        model.load_state_dict(state_dict)
    else:
        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    model.eval()

    # å°†æ¨¡å‹ç§»åŠ¨åˆ° GPU ä¸Š
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    # å®šä¹‰å‡½æ•°æ¥æå–å›¾åƒç‰¹å¾
    def extract_features(image_path):
        img = Image.open(image_path)
        # ç¡®ä¿å›¾åƒæ˜¯ RGB æ ¼å¼
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img_t = preprocess(img)
        img_t = img_t.unsqueeze(0).to(device)
        with torch.no_grad():
            features = model(img_t)
        return features

    # å®šä¹‰å‡½æ•°æ¥è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
    def cosine_similarity(feat1, feat2):
        return F.cosine_similarity(feat1, feat2)

    # è·å–æ–‡ä»¶å¤¹ A å’Œ B ä¸­çš„å›¾ç‰‡è·¯å¾„
    support_images = ('.png', '.jpg', '.jpeg', '.webp', '.avif')
    images_a = [
        str(img_path.absolute())
        for img_path in Path(folder_a).glob('*')
        if img_path.is_file() and img_path.suffix.lower() in support_images
    ]
    images_b = [
        str(img_path.absolute())
        for img_path in Path(folder_b).glob(r_)
        if img_path.is_file() and img_path.suffix.lower() in support_images
    ]

    # ä¸ºæ–‡ä»¶å¤¹ B ä¸­çš„æ¯å¼ å›¾ç‰‡æå–ç‰¹å¾
    features_b = [extract_features(img_path) for img_path in images_b]

    # åˆå§‹åŒ–åŒ¹é…å­—å…¸
    match_dict = []

    # éå†æ–‡ä»¶å¤¹ A ä¸­çš„æ¯å¼ å›¾ç‰‡ï¼Œæ‰¾åˆ°ä¸ä¹‹ç›¸ä¼¼åº¦æœ€é«˜çš„å›¾ç‰‡
    for img_path_a in images_a:
        features_a = extract_features(img_path_a)
        similarities = [cosine_similarity(features_a, features_b[i]).item() for i in range(len(features_b))]
        max_similarity = max(similarities)
        max_similarity_index = similarities.index(max_similarity)
        most_similar_img_path = images_b[max_similarity_index]
        match_dict.append({
            'raw': os.path.basename(img_path_a),
            'rawPath': img_path_a,
            'match': os.path.basename(most_similar_img_path),
            'matchPath': most_similar_img_path,
            'matchRatio': max_similarity
        })
    return {'match_result': match_dict, 'a_num': len(images_a), 'b_num': len(images_b)}


def split_image(img_dir, match_from_son=False):
    r_ = '**/*' if match_from_son else '*'
    images_ = [
        p for p in Path(img_dir).glob(r_)
        if p.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.gif', '.webp'] and p.is_file()
    ]
    for img_path in images_:
        out_dir = img_path.parent
        try:
            with Image.open(img_path) as im:
                width, height = im.size
                if width > height:
                    mid = width // 2
                    left = im.crop((0, 0, mid, height))
                    right = im.crop((mid, 0, width, height))
                    base = img_path.stem
                    ext = img_path.suffix.lower()
                    left_path = out_dir / f"{base}_2{ext}"
                    right_path = out_dir / f"{base}_1{ext}"
                    save_kwargs = {}
                    if ext in {'.jpg', '.jpeg'} and im.mode in ('RGBA', 'LA', 'P'):
                        left = left.convert('RGB')
                        right = right.convert('RGB')
                    if ext == '.png':
                        save_kwargs['compress_level'] = im.info.get('compress_level', 9)
                    icc = im.info.get('icc_profile')
                    if icc:
                        save_kwargs['icc_profile'] = icc
                    left.save(left_path, format=Image.EXTENSION[ext], **save_kwargs)
                    right.save(right_path, format=Image.EXTENSION[ext], **save_kwargs)
                    print(f"æ‹†åˆ†äº†å›¾ç‰‡ï¼šf{img_path}")
        except Exception as e:
            print(f"Failed to process {img_path}: {e}")


def align_images(
        ref_path,
        img_path,
        output_dir="temp_align",
        min_good_matches=100,
        fill_color=(255, 255, 255),  # æ–°å¢ï¼šå¡«å……é¢œè‰²ï¼Œé»˜è®¤ç™½è‰²
        print_log=False
):
    """
    å°† img_path çš„å›¾ç‰‡å¯¹é½åˆ° ref_path çš„å›¾ç‰‡ç©ºé—´ï¼Œå¹¶ä¿å­˜å¯¹é½åçš„ç»“æœã€‚
    æ”¯æŒè‡ªå®šä¹‰ warpPerspective çš„å¡«å……é¢œè‰²ï¼ˆä¾‹å¦‚ç™½è‰² (255,255,255)ï¼‰ã€‚

    å‚æ•°:
        ref_path: ç›®æ ‡å‚è€ƒå›¾ç‰‡è·¯å¾„ï¼ˆen.png é£æ ¼ï¼‰
        img_path: éœ€è¦å¯¹é½çš„å›¾ç‰‡è·¯å¾„ï¼ˆzh.jpg é£æ ¼ï¼‰
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
        min_good_matches: æœ€ä½æœ‰æ•ˆåŒ¹é…ç‚¹æ•°é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è§†ä¸ºå¤±è´¥
        fill_color: å¡«å……åŒºåŸŸçš„é¢œè‰² (B, G, R)ï¼Œé»˜è®¤ (0,0,0) é»‘è‰²

    è¿”å›:
        str | None: å¯¹é½æˆåŠŸæ—¶è¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å› None
    """
    # è¯»å–å›¾ç‰‡
    ref = cv2.imread(ref_path)
    img = cv2.imread(img_path)

    if ref is None or img is None:
        if print_log:
            print(f"è¯»å–å›¾ç‰‡å¤±è´¥ï¼šref={ref_path}, img={img_path}")
        return None

    # è½¬ç°åº¦
    ref_gray = cv2.cvtColor(ref, cv2.COLOR_BGR2GRAY)
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # AKAZE ç‰¹å¾æ£€æµ‹ï¼ˆå¯¹æ¼«ç”»çº¿æ¡å‹å¥½ï¼‰
    detector = cv2.AKAZE_create()
    kp1, des1 = detector.detectAndCompute(ref_gray, None)
    kp2, des2 = detector.detectAndCompute(img_gray, None)

    if des1 is None or des2 is None:
        if print_log:
            print(f"ç‰¹å¾æ£€æµ‹å¤±è´¥ï¼Œæ— æ³•æå–æè¿°å­ï¼šref={ref_path}, img={img_path}")
        return None

    # åŒ¹é… + æ¯”ç‡æµ‹è¯•
    bf = cv2.BFMatcher(cv2.NORM_HAMMING)
    matches = bf.knnMatch(des1, des2, k=2)

    good = []
    for m, n in matches:
        if m.distance < 0.75 * n.distance:
            good.append(m)
    if print_log:
        print(f"æœ‰æ•ˆåŒ¹é…ç‚¹æ•°ï¼š{len(good)}")

    if len(good) < min_good_matches:
        if print_log:
            print(f"åŒ¹é…ç‚¹ä¸è¶³ï¼ˆ{len(good)} < {min_good_matches}ï¼‰ï¼Œå¯¹é½å¤±è´¥ï¼šref={ref_path}, img={img_path}")
        return None

    # æå–åŒ¹é…ç‚¹åæ ‡
    src_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)

    # è®¡ç®—å•åº”çŸ©é˜µ
    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

    inlier_ratio = mask.sum() / len(good) if len(good) > 0 else 0
    if print_log:
        print(f"å†…ç‚¹æ¯”ä¾‹ï¼š{inlier_ratio:.2%}")

    if inlier_ratio < 0.5:
        if print_log:
            print(f"å†…ç‚¹æ¯”ä¾‹è¿‡ä½ï¼Œå¯¹é½ä¸å¯é ï¼šref={ref_path}, img={img_path}")
        return None

    # è¿›è¡Œé€è§†å˜æ¢å¯¹é½ï¼Œæ”¯æŒè‡ªå®šä¹‰å¡«å……é¢œè‰²
    h, w = ref.shape[:2]
    aligned = cv2.warpPerspective(
        img,
        H,
        (w, h),
        borderMode=cv2.BORDER_CONSTANT,
        borderValue=fill_color  # è¿™é‡Œæ§åˆ¶å¡«å……é¢œè‰²
    )

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    base_name = os.path.splitext(os.path.basename(img_path))[0]
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, f"{base_name}_aligned.png")

    # ä¿å­˜
    success = cv2.imwrite(output_path, aligned)
    if not success:
        if print_log:
            print(f"ä¿å­˜å¤±è´¥ï¼š{output_path}ï¼šref={ref_path}, img={img_path}")
        return None
    if print_log:
        print(f"å¯¹é½å®Œæˆï¼Œå·²ä¿å­˜è‡³ï¼š{output_path}")
    return os.path.abspath(os.path.normpath(output_path))


if __name__ == "__main__":
    # # æµ‹è¯•ï¼šæ£€æµ‹æ˜¯å¦é»‘ç™½å›¾
    # test_img_gray = Image.open(r"F:\CH1 Visiting Home (COMIC X-Eros #52) (02).png")
    # print(isGrayMap(test_img_gray, debug=True))

    # æµ‹è¯•ï¼šä½¿å›¾ç‰‡Bå‘å›¾ç‰‡Aå¯¹é½
    aligned_path_white = align_images(ref_path=r"F:\[èµ¤åŸã‚ã•ã²ã¨] åã‚Š (ã‚ã¾â¤ãƒŠãƒ)\09_01.png",
                                      img_path=r"F:\[èµ¤åŸã‚ã•ã²ã¨] åã‚Š (ã‚ã¾â¤ãƒŠãƒ)\æ±‰åŒ–\STARS_18057_132.jpg", )
    if aligned_path_white:
        print(f"æˆåŠŸç”Ÿæˆï¼š{aligned_path_white}")
    else:
        print("å¯¹é½å¤±è´¥")
